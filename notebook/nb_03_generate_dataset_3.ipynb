{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "708162fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60d1b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2e7e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.npz_files import open_npz, open_npz_key, save_npz\n",
    "from utils.features import compute_cwru_features\n",
    "from utils.transform import extract_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b7817e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95fcc2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "RPMS_LIST = [1730, 1750, 1772, 1797]\n",
    "FAULT_LIST = ['IR', 'B', 'OR@6', 'OR@3', 'OR@12']\n",
    "DIAMETER_LIST = [7, 14, 21, 28]\n",
    "END_LIST = ['FE', 'DE12', 'DE48']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3b421",
   "metadata": {},
   "source": [
    "## Create daframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa5f9079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "36817ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_ROWS = 8192\n",
    "NORMAL_ROWS = 8192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "08f5d2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DATA_DIR = '../datasets/step2'\n",
    "ROOT_DATA_SERIES_DIR = '../datasets/step3'\n",
    "os.makedirs(ROOT_DATA_SERIES_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d57b7b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/322 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [00:02<00:00, 159.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_normal.shape (65536, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 322/322 [01:18<00:00,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_anomaly.shape (313344, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# select normal\n",
    "df_normal = None\n",
    "np_normal = None\n",
    "for dirpath, dirnames, filenames in os.walk(ROOT_DATA_DIR):\n",
    "    for fn in tqdm(filenames):\n",
    "        if not \"normal\" in fn.lower() or not fn.endswith(\".parquet\"):\n",
    "            continue\n",
    "\n",
    "        parquet_filepath = os.path.join(dirpath, fn)\n",
    "        df = pd.read_parquet(parquet_filepath)\n",
    "        npdata = open_npz_key(parquet_filepath.replace(\".parquet\", \".npz\"), \"a\")\n",
    "        if df_normal is None:\n",
    "            df_normal = df\n",
    "            np_normal = npdata\n",
    "        else:\n",
    "            df_normal = pd.concat((df_normal, df))\n",
    "            np_normal = np.vstack((np_normal, npdata))\n",
    "\n",
    "# sampling normal\n",
    "print(\"df_normal.shape\", df_normal.shape)\n",
    "num_normal = df_normal.shape[0]\n",
    "index_normal_selected = random.choices(list(range(num_normal)), k=NORMAL_ROWS)\n",
    "df_normal = df_normal.iloc[index_normal_selected]\n",
    "df_normal[\"anomaly\"] = 0\n",
    "# df_normal = df_normal\\\n",
    "#             .sample(NORMAL_ROWS, random_state=RANDOM_SEED)\\\n",
    "#             .reset_index(drop=True)\n",
    "np_normal = np_normal[index_normal_selected]\n",
    "\n",
    "\n",
    "df_anomaly = None\n",
    "np_anomaly = None\n",
    "for dirpath, dirnames, filenames in os.walk(ROOT_DATA_DIR):\n",
    "    for fn in tqdm(filenames):\n",
    "        if \"normal\" in fn.lower() or not fn.endswith(\".parquet\"):\n",
    "            continue\n",
    "\n",
    "        parquet_filepath = os.path.join(dirpath, fn)\n",
    "        df = pd.read_parquet(parquet_filepath)\n",
    "        npdata = open_npz_key(parquet_filepath.replace(\".parquet\", \".npz\"), \"a\")\n",
    "        if df_anomaly is None:\n",
    "            df_anomaly = df\n",
    "            np_anomaly = npdata\n",
    "        else:\n",
    "            df_anomaly = pd.concat((df_anomaly, df))\n",
    "            np_anomaly = np.vstack((np_anomaly, npdata))\n",
    "\n",
    "# sampling anomaly\n",
    "print(\"df_anomaly.shape\", df_anomaly.shape)\n",
    "num_anomaly = df_anomaly.shape[0]\n",
    "index_anomaly_selected = random.choices(list(range(num_anomaly)), k=ANOMALY_ROWS)\n",
    "df_anomaly = df_anomaly.iloc[index_anomaly_selected]\n",
    "df_anomaly[\"anomaly\"] = 1\n",
    "# df_anomaly = df_anomaly\\\n",
    "#             .sample(ANOMALY_ROWS, random_state=RANDOM_SEED)\\\n",
    "#             .reset_index(drop=True)\n",
    "np_anomaly = np_anomaly[index_anomaly_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5bcae484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((df_normal, df_anomaly))\n",
    "np_data = np.vstack((np_normal, np_anomaly))\n",
    "\n",
    "\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "index_all = list(range(np_data.shape[0]))\n",
    "random.shuffle(index_all)\n",
    "\n",
    "\n",
    "df = df.iloc[index_all]\n",
    "np_data = np_data[index_all]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09c4ca2",
   "metadata": {},
   "source": [
    "### Dataset 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0bc0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_COLUMNS = [\n",
    "    \"maximum\",\n",
    "    \"minimum\",\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"rms\",\n",
    "    \"skewness\",\n",
    "    \"kurtosis\",\n",
    "    \"crest_factor\",\n",
    "    \"form_factor\",\n",
    "    \"rpm\",\n",
    "    \"anomaly_type\",\n",
    "    \"diameter_fault\",\n",
    "    \"sampling_value\",\n",
    "    \"sampling_label\",\n",
    "    \"accelerometer\",\n",
    "    \"anomaly\"\n",
    "]\n",
    "\n",
    "df3 = df.copy()\n",
    "df3 = df3[SELECTED_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "023f42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = os.path.join(ROOT_DATA_SERIES_DIR, \"dataset.parquet\")\n",
    "df3.to_parquet(output_filename, index=False)\n",
    "save_npz(output_filename.replace(\".parquet\", \".npz\"), a=np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "455b966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_parquet(output_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9f3f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maximum</th>\n",
       "      <th>minimum</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>rms</th>\n",
       "      <th>skewness</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>crest_factor</th>\n",
       "      <th>form_factor</th>\n",
       "      <th>rpm</th>\n",
       "      <th>anomaly_type</th>\n",
       "      <th>diameter_fault</th>\n",
       "      <th>sampling_value</th>\n",
       "      <th>sampling_label</th>\n",
       "      <th>accelerometer</th>\n",
       "      <th>anomaly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9858</th>\n",
       "      <td>0.453233</td>\n",
       "      <td>-0.329549</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.099538</td>\n",
       "      <td>0.103937</td>\n",
       "      <td>0.012034</td>\n",
       "      <td>0.664501</td>\n",
       "      <td>4.360630</td>\n",
       "      <td>1.270665</td>\n",
       "      <td>1772</td>\n",
       "      <td>IR</td>\n",
       "      <td>14.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>DE4</td>\n",
       "      <td>FE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2932</th>\n",
       "      <td>0.222593</td>\n",
       "      <td>-0.238447</td>\n",
       "      <td>0.011302</td>\n",
       "      <td>0.065588</td>\n",
       "      <td>0.066539</td>\n",
       "      <td>-0.198584</td>\n",
       "      <td>0.154071</td>\n",
       "      <td>3.345287</td>\n",
       "      <td>1.255593</td>\n",
       "      <td>1730</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12843</th>\n",
       "      <td>0.280651</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.033720</td>\n",
       "      <td>0.066050</td>\n",
       "      <td>0.074145</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>-0.107158</td>\n",
       "      <td>3.785149</td>\n",
       "      <td>1.261062</td>\n",
       "      <td>1772</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>FE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0.220715</td>\n",
       "      <td>-0.200479</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.070482</td>\n",
       "      <td>0.071546</td>\n",
       "      <td>0.024511</td>\n",
       "      <td>-0.272400</td>\n",
       "      <td>3.084943</td>\n",
       "      <td>1.236751</td>\n",
       "      <td>1797</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>DE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2677</th>\n",
       "      <td>1.009398</td>\n",
       "      <td>-1.182185</td>\n",
       "      <td>0.032005</td>\n",
       "      <td>0.222738</td>\n",
       "      <td>0.224972</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>2.483487</td>\n",
       "      <td>4.486779</td>\n",
       "      <td>1.366400</td>\n",
       "      <td>1730</td>\n",
       "      <td>OR@3</td>\n",
       "      <td>21.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>DE1</td>\n",
       "      <td>FE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        maximum   minimum      mean       std       rms  skewness  kurtosis  \\\n",
       "9858   0.453233 -0.329549  0.029999  0.099538  0.103937  0.012034  0.664501   \n",
       "2932   0.222593 -0.238447  0.011302  0.065588  0.066539 -0.198584  0.154071   \n",
       "12843  0.280651 -0.182444  0.033720  0.066050  0.074145  0.141900 -0.107158   \n",
       "5156   0.220715 -0.200479  0.012389  0.070482  0.071546  0.024511 -0.272400   \n",
       "2677   1.009398 -1.182185  0.032005  0.222738  0.224972  0.003637  2.483487   \n",
       "\n",
       "       crest_factor  form_factor   rpm anomaly_type  diameter_fault  \\\n",
       "9858       4.360630     1.270665  1772           IR            14.0   \n",
       "2932       3.345287     1.255593  1730         None             NaN   \n",
       "12843      3.785149     1.261062  1772         None             NaN   \n",
       "5156       3.084943     1.236751  1797         None             NaN   \n",
       "2677       4.486779     1.366400  1730         OR@3            21.0   \n",
       "\n",
       "       sampling_value sampling_label accelerometer  anomaly  \n",
       "9858             48.0            DE4            FE        1  \n",
       "2932              NaN           None            DE        0  \n",
       "12843             NaN           None            FE        0  \n",
       "5156              NaN           None            DE        0  \n",
       "2677             12.0            DE1            FE        1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ad0eb9",
   "metadata": {},
   "source": [
    "### Dataset 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2dd600cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECTED_COLUMNS = [\n",
    "    \"maximum\",\n",
    "    \"minimum\",\n",
    "    \"mean\",\n",
    "    \"std\",\n",
    "    \"rms\",\n",
    "    \"skewness\",\n",
    "    \"kurtosis\",\n",
    "    \"crest_factor\",\n",
    "    \"form_factor\",\n",
    "    \"thd\",\n",
    "    \"f0\",\n",
    "    \"rpm\",\n",
    "    \"anomaly_type\",\n",
    "    \"diameter_fault\",\n",
    "    \"sampling_value\",\n",
    "    \"sampling_label\",\n",
    "    \"accelerometer\",\n",
    "    \"anomaly\"\n",
    "]\n",
    "\n",
    "df5 = df.copy()\n",
    "df5 = df5[SELECTED_COLUMNS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7597eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../datasets/step4'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m output_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../datasets/step4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdf5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m save_npz(output_filename\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.npz\u001b[39m\u001b[38;5;124m\"\u001b[39m), a\u001b[38;5;241m=\u001b[39mnp_data)\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/core/frame.py:3118\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;124;03mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   3039\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3114\u001b[0m \u001b[38;5;124;03m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   3115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3116\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 3118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_parquet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/io/parquet.py:482\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m impl \u001b[38;5;241m=\u001b[39m get_engine(engine)\n\u001b[1;32m    480\u001b[0m path_or_buf: FilePath \u001b[38;5;241m|\u001b[39m WriteBuffer[\u001b[38;5;28mbytes\u001b[39m] \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO() \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m path\n\u001b[0;32m--> 482\u001b[0m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartition_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, io\u001b[38;5;241m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/io/parquet.py:199\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m     merged_metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexisting_metadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdf_metadata}\n\u001b[1;32m    197\u001b[0m     table \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(merged_metadata)\n\u001b[0;32m--> 199\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpartition_cols\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(path_or_handle, io\u001b[38;5;241m.\u001b[39mBufferedWriter)\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(path_or_handle, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle\u001b[38;5;241m.\u001b[39mname, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m))\n\u001b[1;32m    210\u001b[0m ):\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_handle\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mbytes\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/io/parquet.py:141\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    131\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 141\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cwru/lib/python3.13/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../datasets/step4'"
     ]
    }
   ],
   "source": [
    "OUTPUT_STEP4_DIR = '../datasets/step4'\n",
    "os.makedirs(OUTPUT_STEP4_DIR)\n",
    "output_filename = os.path.join(OUTPUT_STEP4_DIR, \"dataset.parquet\")\n",
    "df5.to_parquet(output_filename, index=False)\n",
    "save_npz(output_filename.replace(\".parquet\", \".npz\"), a=np_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cwru",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
